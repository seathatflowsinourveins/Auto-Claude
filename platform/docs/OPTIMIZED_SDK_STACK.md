# Optimized Unleashed SDK Stack - Research Results

**Generated:** 2026-01-19
**Ralph Loop Iteration:** 2/10
**Research Method:** Exa Deep Research Pro (6 parallel tasks)

---

## Executive Summary

After comprehensive deep research across 6 SDK layers, here are the **best-in-class SDKs** for the Unleashed platform:

| Layer | Winner | Stars | Why |
|-------|--------|-------|-----|
| **OPTIMIZATION** | DSPy | 31.6k | Production-ready, Stanford NLP, v3.1 stable |
| **ORCHESTRATION** | LangGraph | 23.5k | Enterprise adoption, stateful graphs |
| **MEMORY** | Mem0 | 45.7k | Highest adoption, flexible backends |
| **REASONING** | llm-reasoners | 2.3k | All-in-one: ToT, GoT, CoT, MCTS |
| **RESEARCH** | Exa + Firecrawl | N/A | Best semantic search + extraction combo |
| **CODE** | Aider + Serena | 39.9k + 18.9k | CLI pair programming + LSP analysis |

---

## Layer 1: OPTIMIZATION

### Winner: DSPy (Stanford NLP)
- **Repository:** https://github.com/stanfordnlp/dspy
- **Stars:** 31,600 | **Forks:** 2,600 | **Commits:** 4,333
- **Latest:** v3.1.0 (Jan 2026)
- **License:** MIT

**Why DSPy:**
- Declarative prompt programming (no brittle strings)
- Modular, composable pipelines
- Automatic prompt and weight optimization
- 1,400+ production dependents
- Comprehensive docs at dspy.ai

### Runner-up: TextGrad
- **Repository:** https://github.com/zou-group/textgrad
- **Stars:** 3,300 | Nature publication (Mar 2025)
- **Use for:** Research/experimental gradient-based optimization

### Also Consider: Promptomatix (Salesforce)
- **Repository:** https://github.com/SalesforceAIResearch/promptomatix
- **Stars:** 873 | Apache-2.0 | Enterprise-focused

---

## Layer 2: ORCHESTRATION

### Winner: LangGraph (LangChain)
- **Repository:** https://github.com/langchain-ai/langgraph
- **Stars:** 23,500 | **Forks:** 4,100 | **Commits:** 6,454
- **License:** MIT

**Why LangGraph:**
- State graph architecture (nodes + edges)
- Durable execution with checkpointing
- Human-in-the-loop interrupts
- Enterprise adoption: Replit, Uber, LinkedIn, GitLab
- Memory integration modules

### Strong Alternatives:

**CrewAI** - Enterprise Control Plane
- **Repository:** https://github.com/crewAIInc/crewAI
- **Stars:** 42,900 | Mission-critical automation
- **Use for:** Enterprise fleet management

**mcp-agent** - MCP-Native Workflows
- **Repository:** https://github.com/lastmile-ai/mcp-agent
- **Stars:** 8,000 | Deep orchestrator pattern
- **Use for:** MCP-first architectures

**AutoGen** (Microsoft)
- **Repository:** https://github.com/microsoft/autogen
- **Stars:** 53,700 | Cross-platform (.NET + Python)
- **Use for:** Microsoft ecosystem integration

**EvoAgentX** - Self-Evolving Agents
- **Repository:** https://github.com/EvoAgentX/EvoAgentX
- **Stars:** 2,500 | Genetic workflow evolution
- **Use for:** Automated workflow improvement

---

## Layer 3: MEMORY

### Winner: Mem0
- **Repository:** https://github.com/mem0ai/mem0
- **Stars:** 45,700 | **Forks:** 5,000 | **Commits:** 1,888
- **Latest:** v1.0.0 (2026)
- **License:** MIT

**Why Mem0:**
- Universal memory layer for AI assistants
- Multiple backends: SQLite, Supabase, Pinecone, Weaviate
- Graph memory with Neo4j support
- MCP protocol compatible
- Highest community adoption

### Strong Alternatives:

**Letta** (formerly MemGPT)
- **Repository:** https://github.com/letta-ai/letta
- **Stars:** 20,700 | Stateful agents
- **Memory SDK:** https://github.com/letta-ai/ai-memory-sdk
- **Use for:** Advanced stateful agent architectures

**Graphiti** (Zep)
- **Repository:** https://github.com/getzep/graphiti
- **Stars:** 480 | Temporal knowledge graphs
- **Use for:** Time-aware graph contexts

**LangMem** (LangChain)
- **Repository:** https://github.com/langchain-ai/langmem
- **Stars:** 1,500 | LangChain-native
- **Use for:** LangChain ecosystem integration

---

## Layer 4: REASONING

### Winner: llm-reasoners (Maitrix)
- **Repository:** https://github.com/maitrix-org/llm-reasoners
- **Stars:** 2,300 | **Forks:** 203 | **Commits:** 904
- **License:** MIT

**Why llm-reasoners:**
- All-in-one: ToT, GoT, CoT, MCTS, PRM
- Interactive visualization tool
- Tutorial notebooks included
- Inference-time scaling support
- Active development

### Specialized Alternatives:

**Graph-of-Thoughts** (ETH Zurich)
- **Repository:** https://github.com/spcl/graph-of-thoughts
- **Stars:** 2,600 | Official GoT implementation
- **Use for:** Pure graph-based reasoning

**Tree-of-Thoughts** (Princeton NLP)
- **Repository:** https://github.com/princeton-nlp/tree-of-thought-llm
- **Stars:** 5,800 | Official ToT (NeurIPS 2023)
- **Use for:** Tree search reasoning

**Auto-CoT** (Amazon)
- **Repository:** https://github.com/amazon-science/auto-cot
- **Stars:** 3,500 | Automatic prompt design
- **Use for:** Zero-shot reasoning

**Cogitator**
- **Repository:** https://github.com/habedi/cogitator
- **Stars:** 1,200 | CoT variants toolkit
- **Use for:** Prompt-based CoT

---

## Layer 5: RESEARCH & EXTRACTION

### Winner Combo: Exa AI + Firecrawl

**Exa AI** - Semantic Search
- **Repository:** https://github.com/exa-labs/ai-sdk
- **API:** exa.ai
- **Accuracy:** 96% retrieval (FRAMES benchmark)
- **Pricing:** $5/1k searches, $15/1k deep searches

**Firecrawl** - Web Extraction
- **Repository:** https://github.com/mendableai/firecrawl
- **Accuracy:** >90% structured extraction
- **Features:** LLM-driven schema extraction

### Also Recommended:

**Open Deep Research** (LangChain)
- **Repository:** https://github.com/langchain-ai/open_deep_research
- **Use for:** Full agentic research pipelines

**Crawl4AI**
- **Repository:** https://github.com/unclecode/crawl4ai
- **Stars:** Self-hosted, LLM-optimized
- **Use for:** High-volume local crawling

**Tavily**
- **Repository:** https://github.com/tavily-ai/tavily-python
- **Use for:** Real-time search with low latency

---

## Layer 6: CODE ANALYSIS

### Winner Combo: Aider + Serena

**Aider** - AI Pair Programming
- **Repository:** https://github.com/Aider-AI/aider
- **Stars:** 39,900 | **Commits:** 13,000
- **Languages:** 100+ supported
- **Accuracy:** 84-90% (benchmark)

**Serena** - Semantic Code Analysis
- **Repository:** https://github.com/oraios/serena
- **Stars:** 18,900 | **Forks:** 1,300
- **Languages:** 30+ via LSP
- **Features:** MCP server, symbol-level operations

### Also Recommended:

**Continue.dev**
- **Repository:** https://github.com/continuedev/continue
- **Stars:** 31,000 | Rule-driven CI agents
- **Use for:** PR automation

---

## Recommended Architecture

```
┌─────────────────────────────────────────────────────────────────┐
│                    UNLEASHED PLATFORM v2.0                      │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  OPTIMIZATION LAYER                                             │
│  └── DSPy v3.1 ────────────────────────────────────────────────│
│      └── Declarative prompt compilation & optimization          │
│                                                                 │
│  ORCHESTRATION LAYER                                            │
│  ├── LangGraph ──────── Stateful workflows, checkpointing      │
│  ├── mcp-agent ──────── MCP-native deep orchestrator           │
│  └── EvoAgentX ──────── Self-evolving workflow optimization    │
│                                                                 │
│  MEMORY LAYER                                                   │
│  ├── Mem0 ───────────── Universal memory (SQLite/Supabase)     │
│  ├── Letta ──────────── Stateful agent memory blocks           │
│  └── Graphiti ───────── Temporal knowledge graphs (Neo4j)      │
│                                                                 │
│  REASONING LAYER                                                │
│  ├── llm-reasoners ──── ToT, GoT, CoT, MCTS unified            │
│  ├── UnifiedThinking ── Custom GoT/ToT (already implemented)   │
│  └── Sequential MCP ─── Step-by-step reasoning server          │
│                                                                 │
│  RESEARCH LAYER                                                 │
│  ├── Exa AI ─────────── Semantic search (96% accuracy)         │
│  ├── Firecrawl ──────── LLM-driven extraction                  │
│  ├── Crawl4AI ───────── Self-hosted deep crawling              │
│  └── Open Deep Research Agent pipeline                         │
│                                                                 │
│  CODE LAYER                                                     │
│  ├── Aider ──────────── AI pair programming (CLI)              │
│  ├── Serena ─────────── LSP-based semantic analysis            │
│  └── Continue.dev ───── Rule-driven automation                 │
│                                                                 │
│  SELF-IMPROVEMENT LAYER                                         │
│  ├── Ralph Loop ─────── Iterative refinement (active)          │
│  ├── EvoAgentX ──────── Genetic workflow evolution             │
│  └── TextGrad ───────── Gradient-based optimization            │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## Repositories to Clone

Priority order for local installation:

```bash
# TIER 1: Core SDKs (must-have)
git clone https://github.com/stanfordnlp/dspy.git
git clone https://github.com/langchain-ai/langgraph.git
git clone https://github.com/mem0ai/mem0.git
git clone https://github.com/maitrix-org/llm-reasoners.git
git clone https://github.com/Aider-AI/aider.git

# TIER 2: Orchestration & Memory
git clone https://github.com/lastmile-ai/mcp-agent.git
git clone https://github.com/EvoAgentX/EvoAgentX.git
git clone https://github.com/letta-ai/letta.git
git clone https://github.com/getzep/graphiti.git

# TIER 3: Research & Code
git clone https://github.com/mendableai/firecrawl.git
git clone https://github.com/unclecode/crawl4ai.git
git clone https://github.com/oraios/serena.git
git clone https://github.com/langchain-ai/open_deep_research.git

# TIER 4: Reasoning Specialized
git clone https://github.com/spcl/graph-of-thoughts.git
git clone https://github.com/princeton-nlp/tree-of-thought-llm.git
git clone https://github.com/amazon-science/auto-cot.git

# TIER 5: Optimization & Enhancement
git clone https://github.com/zou-group/textgrad.git
git clone https://github.com/continuedev/continue.git
```

---

## Integration Priorities

1. **Phase 1:** DSPy + LangGraph + Mem0 (Core pipeline)
2. **Phase 2:** llm-reasoners integration with UnifiedThinking
3. **Phase 3:** EvoAgentX for self-improving workflows
4. **Phase 4:** Serena MCP for code understanding
5. **Phase 5:** Full research pipeline with Open Deep Research

---

## Quality Metrics Summary

| SDK | Stars | Commits | Last Release | Maintenance | Score |
|-----|-------|---------|--------------|-------------|-------|
| DSPy | 31.6k | 4,333 | Jan 2026 | Very High | 95/100 |
| LangGraph | 23.5k | 6,454 | Monthly | Very High | 93/100 |
| Mem0 | 45.7k | 1,888 | v1.0 2026 | Very High | 94/100 |
| llm-reasoners | 2.3k | 904 | Active | High | 88/100 |
| Aider | 39.9k | 13,000 | Weekly | Very High | 92/100 |
| Serena | 18.9k | 2,000 | Active | High | 89/100 |
| mcp-agent | 8.0k | 766 | Active | High | 87/100 |
| EvoAgentX | 2.5k | 1,050 | Active | Medium | 82/100 |

---

*Document generated by Ralph Loop Iteration 2 - Unleashed Platform Optimization*
